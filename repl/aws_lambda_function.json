{
  "resource": {
    "lambda_event_source_mapping": {
      "amazon_managed_kafka_event_source_config": "(Optional) Additional configuration block for Amazon Managed Kafka sources. Incompatible with \"self_managed_event_source\" and \"self_managed_kafka_event_source_config\". Detailed below.",
      "batch_size": "(Optional) The largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to `100` for DynamoDB, Kinesis, MQ and MSK, `10` for SQS.",
      "enabled": "(Optional) Determines if the mapping will be enabled on creation. Defaults to `true`.",
      "event_source_arn": "(Optional) The event source ARN - this is required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream.  It is incompatible with a Self Managed Kafka source.",
      "filter_criteria": "(Optional) The criteria to use for [event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html) Kinesis stream, DynamoDB stream, SQS queue event sources. Detailed below.",
      "function_name": "(Required) The name or the ARN of the Lambda function that will be subscribing to events.",
      "function_response_types": "(Optional) A list of current response type enums applied to the event source mapping for [AWS Lambda checkpointing](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting). Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: `ReportBatchItemFailures`.",
      "maximum_batching_window_in_seconds": "(Optional) The maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer (or accumulate in the case of an SQS queue event source) until either `maximum_batching_window_in_seconds` expires or `batch_size` has been met. For streaming event sources, defaults to as soon as records are available in the stream. If the batch it reads from the stream/queue only has one record in it, Lambda only sends one record to the function. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.",
      "queues": "(Optional) The name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.",
      "scaling_config": "(Optional) Scaling configuration of the event source. Only available for SQS queues. Detailed below.",
      "self_managed_kafka_event_source_config": "(Optional) Additional configuration block for Self Managed Kafka sources. Incompatible with \"event_source_arn\" and \"amazon_managed_kafka_event_source_config\". Detailed below.",
      "starting_position": "(Optional) The position in the stream where AWS Lambda should start reading. Must be one of `AT_TIMESTAMP` (Kinesis only), `LATEST` or `TRIM_HORIZON` if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the [AWS DynamoDB Streams API Reference](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetShardIterator.html) and [AWS Kinesis API Reference](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType).",
      "starting_position_timestamp": "(Optional) A timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) of the data record which to start reading when using `starting_position` set to `AT_TIMESTAMP`. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.",
      "topics": "(Optional) The name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.",
      "tumbling_window_in_seconds": "(Optional) The duration in seconds of a processing window for [AWS Lambda streaming analytics](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-windows). The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).",
      "consumer_group_id": "(Optional) A Kafka consumer group ID between 1 and 200 characters for use when creating this event source mapping. If one is not specified, this value will be automatically generated. See [SelfManagedKafkaEventSourceConfig Syntax](https://docs.aws.amazon.com/lambda/latest/dg/API_SelfManagedKafkaEventSourceConfig.html).",
      "on_failure": "(Optional) The destination configuration for failed invocations. Detailed below.",
      "destination_arn": "(Required) The Amazon Resource Name (ARN) of the destination resource.",
      "collection_name": "(Optional) The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.",
      "database_name": "(Required) The name of the database to consume within the DocumentDB cluster.",
      "full_document": "(Optional) Determines what DocumentDB sends to your event stream during document update operations. If set to `UpdateLookup`, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes. Valid values: `UpdateLookup`, `Default`.",
      "filter": "(Optional) A set of up to 5 filter. If an event satisfies at least one, Lambda sends the event to the function or adds it to the next batch. Detailed below.",
      "pattern": "(Optional) A filter pattern up to 4096 characters. See [Filter Rule Syntax](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-syntax).",
      "maximum_concurrency": "(Optional) Limits the number of concurrent instances that the Amazon SQS event source can invoke. Must be between `2` and `1000`. See [Configuring maximum concurrency for Amazon SQS event sources](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency).",
      "endpoints": "(Required) A map of endpoints for the self managed source.  For Kafka self-managed sources, the key should be `KAFKA_BOOTSTRAP_SERVERS` and the value should be a string with a comma separated list of broker endpoints.",
      "type": "(Required) The type of this configuration.  For Self Managed Kafka you will need to supply blocks for type `VPC_SUBNET` and `VPC_SECURITY_GROUP`.",
      "uri": "(Required) The URI for this configuration.  For type `VPC_SUBNET` the value should be `subnet:subnet_id` where `subnet_id` is the value you would find in an aws_subnet resource's id attribute.  For type `VPC_SECURITY_GROUP` the value should be `security_group:security_group_id` where `security_group_id` is the value you would find in an aws_security_group resource's id attribute."
    },
    "lambda_invocation": {
      "function_name": "(Required) Name of the lambda function.",
      "input": "(Required) JSON payload to the lambda function.",
      "lifecycle_scope": "(Optional) Lifecycle scope of the resource to manage. Valid values are `CREATE_ONLY` and `CRUD`. Defaults to `CREATE_ONLY`. `CREATE_ONLY` will invoke the function only on creation or replacement. `CRUD` will invoke the function on each lifecycle event, and augment the input JSON payload with additional lifecycle information.",
      "qualifier": "(Optional) Qualifier (i.e., version) of the lambda function. Defaults to `$LATEST`.",
      "terraform_key": "(Optional) The JSON key used to store lifecycle information in the input JSON payload. Defaults to `tf`. This additional key is only included when `lifecycle_scope` is set to `CRUD`.",
      "triggers": "(Optional) Map of arbitrary keys and values that, when changed, will trigger a re-invocation. To force a re-invocation without changing these keys/values, use the [`terraform taint` command](https://www.terraform.io/docs/commands/taint.html)."
    },
    "lambda_permission": {
      "action": "(Required) The AWS Lambda action you want to allow in this statement. (e.g., `lambda:InvokeFunction`)",
      "event_source_token": "(Optional) The Event Source Token to validate.  Used with [Alexa Skills][1].",
      "function_name": "(Required) Name of the Lambda function whose resource policy you are updating",
      "function_url_auth_type": "(Optional) Lambda Function URLs [authentication type][3]. Valid values are: `AWS_IAM` or `NONE`. Only supported for `lambda:InvokeFunctionUrl` action.",
      "principal": "(Required) The principal who is getting this permission e.g., `s3.amazonaws.com`, an AWS account ID, or AWS IAM principal, or AWS service principal such as `events.amazonaws.com` or `sns.amazonaws.com`.",
      "qualifier": "(Optional) Query parameter to specify function version or alias name. The permission will then apply to the specific qualified ARN e.g., `arn:aws:lambda:aws-region:acct-id:function:function-name:2`",
      "source_account": "(Optional) This parameter is used when allowing cross-account access, or for S3 and SES. The AWS account ID (without a hyphen) of the source owner.",
      "source_arn": "(Optional) When the principal is an AWS service, the ARN of the specific resource within that service to grant permission to.",
      "statement_id": "(Optional) A unique statement identifier. By default generated by Terraform.",
      "statement_id_prefix": "(Optional) A statement identifier prefix. Terraform will generate a unique suffix. Conflicts with `statement_id`.",
      "principal_org_id": "(Optional) The identifier for your organization in AWS Organizations. Use this to grant permissions to all the AWS accounts under this organization."
    },
    "lambda_provisioned_concurrency_config": {
      "function_name": "(Required) Name or Amazon Resource Name (ARN) of the Lambda Function.",
      "provisioned_concurrent_executions": "(Required) Amount of capacity to allocate. Must be greater than or equal to `1`.",
      "qualifier": "(Required) Lambda Function version or Lambda Alias name.",
      "skip_destroy": "(Optional) Whether to retain the provisoned concurrency configuration upon destruction. Defaults to `false`. If set to `true`, the resource in simply removed from state instead."
    },
    "lambda_layer_version": {
      "layer_name": "(Required) Unique name for your Lambda Layer",
      "compatible_architectures": "(Optional) List of [Architectures][4] this layer is compatible with. Currently `x86_64` and `arm64` can be specified.",
      "compatible_runtimes": "(Optional) List of [Runtimes][2] this layer is compatible with. Up to 5 runtimes can be specified.",
      "description": "(Optional) Description of what your Lambda Layer does.",
      "license_info": "(Optional) License info for your Lambda Layer. See [License Info][3].",
      "s3_bucket": "(Optional) S3 bucket location containing the function's deployment package. Conflicts with `filename`. This bucket must reside in the same AWS region where you are creating the Lambda function.",
      "s3_key": "(Optional) S3 key of an object containing the function's deployment package. Conflicts with `filename`.",
      "s3_object_version": "(Optional) Object version containing the function's deployment package. Conflicts with `filename`.",
      "skip_destroy": "(Optional) Whether to retain the old version of a previously deployed Lambda Layer. Default is `false`. When this is not set to `true`, changing any of `compatible_architectures`, `compatible_runtimes`, `description`, `filename`, `layer_name`, `license_info`, `s3_bucket`, `s3_key`, `s3_object_version`, or `source_code_hash` forces deletion of the existing layer version and creation of a new layer version.",
      "source_code_hash": "(Optional) Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the package file specified with either `filename` or `s3_key`. The usual way to set this is `${filebase64sha256(\"file.zip\")}` (Terraform 0.11.12 or later) or `${base64sha256(file(\"file.zip\"))}` (Terraform 0.11.11 and earlier), where \"file.zip\" is the local filename of the lambda layer source archive."
    },
    "lambda_function": {
      "function_name": "(Required) Unique name for your Lambda Function.",
      "role": "(Required) Amazon Resource Name (ARN) of the function's execution role. The role provides the function's identity and access to AWS services and resources.",
      "architectures": "(Optional) Instruction set architecture for your Lambda function. Valid values are `[\"x86_64\"]` and `[\"arm64\"]`. Default is `[\"x86_64\"]`. Removing this attribute, function's architecture stay the same.",
      "code_signing_config_arn": "(Optional) To enable code signing for this function, specify the ARN of a code-signing configuration. A code-signing configuration includes a set of signing profiles, which define the trusted publishers for this function.",
      "dead_letter_config": {
        "target_arn": "(Required) ARN of an SNS topic or SQS queue to notify when an invocation fails. If this option is used, the function's IAM role must be granted suitable access to write to the target object, which means allowing either the `sns:Publish` or `sqs:SendMessage` action on this ARN, depending on which service is targeted."
      },
      "description": "(Optional) Description of what your Lambda Function does.",
      "environment": {
        "variables": "(Optional) Map of environment variables that are accessible from the function code during execution. If provided at least one key must be present."
      },
      "ephemeral_storage": {
        "size": "(Required) The size of the Lambda function Ephemeral storage(`/tmp`) represented in MB. The minimum supported `ephemeral_storage` value defaults to `512`MB and the maximum supported value is `10240`MB."
      },
      "file_system_config": {
        "arn": "(Required) Amazon Resource Name (ARN) of the Amazon EFS Access Point that provides access to the file system.",
        "local_mount_path": "(Required) Path where the function can access the file system, starting with /mnt/."
      },
      "filename": "(Optional) Path to the function's deployment package within the local filesystem. Exactly one of `filename`, `image_uri`, or `s3_bucket` must be specified.",
      "handler": "(Optional) Function [entrypoint][3] in your code.",
      "image_config": {
        "command": "(Optional) Parameters that you want to pass in with `entry_point`.",
        "entry_point": "(Optional) Entry point to your application, which is typically the location of the runtime executable.",
        "working_directory": "(Optional) Working directory."
      },
      "image_uri": "(Optional) ECR image URI containing the function's deployment package. Exactly one of `filename`, `image_uri`,  or `s3_bucket` must be specified.",
      "kms_key_arn": "(Optional) Amazon Resource Name (ARN) of the AWS Key Management Service (KMS) key that is used to encrypt environment variables. If this configuration is not provided when environment variables are in use, AWS Lambda uses a default service key. If this configuration is provided when environment variables are not in use, the AWS Lambda API does not save this configuration and Terraform will show a perpetual difference of adding the key. To fix the perpetual difference, remove this configuration.",
      "layers": "(Optional) List of Lambda Layer Version ARNs (maximum of 5) to attach to your Lambda Function. See [Lambda Layers][10]",
      "memory_size": "(Optional) Amount of memory in MB your Lambda Function can use at runtime. Defaults to `128`. See [Limits][5]",
      "package_type": "(Optional) Lambda deployment package type. Valid values are `Zip` and `Image`. Defaults to `Zip`.",
      "publish": "(Optional) Whether to publish creation/change as new Lambda Function Version. Defaults to `false`.",
      "reserved_concurrent_executions": "(Optional) Amount of reserved concurrent executions for this lambda function. A value of `0` disables lambda from being triggered and `-1` removes any concurrency limitations. Defaults to Unreserved Concurrency Limits `-1`. See [Managing Concurrency][9]",
      "replace_security_groups_on_destroy": "(Optional, **Deprecated**) **AWS no longer supports this operation. This attribute now has no effect and will be removed in a future major version.** Whether to replace the security groups on associated lambda network interfaces upon destruction. Removing these security groups from orphaned network interfaces can speed up security group deletion times by avoiding a dependency on AWS's internal cleanup operations. By default, the ENI security groups will be replaced with the `default` security group in the function's VPC. Set the `replacement_security_group_ids` attribute to use a custom list of security groups for replacement.",
      "replacement_security_group_ids": "(Optional, **Deprecated**) List of security group IDs to assign to orphaned Lambda function network interfaces upon destruction. `replace_security_groups_on_destroy` must be set to `true` to use this attribute.",
      "runtime": "(Optional) Identifier of the function's runtime. See [Runtimes][6] for valid values.",
      "s3_bucket": "(Optional) S3 bucket location containing the function's deployment package. This bucket must reside in the same AWS region where you are creating the Lambda function. Exactly one of `filename`, `image_uri`, or `s3_bucket` must be specified. When `s3_bucket` is set, `s3_key` is required.",
      "s3_key": "(Optional) S3 key of an object containing the function's deployment package. When `s3_bucket` is set, `s3_key` is required.",
      "s3_object_version": "(Optional) Object version containing the function's deployment package. Conflicts with `filename` and `image_uri`.",
      "skip_destroy": "(Optional) Set to true if you do not wish the function to be deleted at destroy time, and instead just remove the function from the Terraform state.",
      "source_code_hash": "(Optional) Used to trigger updates. Must be set to a base64-encoded SHA256 hash of the package file specified with either `filename` or `s3_key`. The usual way to set this is `filebase64sha256(\"file.zip\")` (Terraform 0.11.12 and later) or `base64sha256(file(\"file.zip\"))` (Terraform 0.11.11 and earlier), where \"file.zip\" is the local filename of the lambda function source archive.",
      "snap_start": {
        "apply_on": "(Required) Conditions where snap start is enabled. Valid values are `PublishedVersions`."
      },
      "tags": "(Optional) Map of tags to assign to the object. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.",
      "timeout": "(Optional) Amount of time your Lambda Function has to run in seconds. Defaults to `3`. See [Limits][5].",
      "tracing_config": {
        "mode": "(Required) Whether to sample and trace a subset of incoming requests with AWS X-Ray. Valid values are `PassThrough` and `Active`. If `PassThrough`, Lambda will only trace the request from an upstream service if it contains a tracing header with \"sampled=1\". If `Active`, Lambda will respect any tracing header it receives from an upstream service. If no tracing header is received, Lambda will call X-Ray for a tracing decision."
      },
      "vpc_config": {
        "security_group_ids": "(Required) List of security group IDs associated with the Lambda function.",
        "subnet_ids": "(Required) List of subnet IDs associated with the Lambda function."
      }
    },
    "lambda_function_url": {
      "authorization_type": "(Required) The type of authentication that the function URL uses. Set to `\"AWS_IAM\"` to restrict access to authenticated IAM users only. Set to `\"NONE\"` to bypass IAM authentication and create a public endpoint. See the [AWS documentation](https://docs.aws.amazon.com/lambda/latest/dg/urls-auth.html) for more details.",
      "cors": {
        "allow_credentials": "(Optional) Whether to allow cookies or other credentials in requests to the function URL. The default is `false`.",
        "allow_headers": "(Optional) The HTTP headers that origins can include in requests to the function URL. For example: `[\"date\", \"keep-alive\", \"x-custom-header\"]`.",
        "allow_methods": "(Optional) The HTTP methods that are allowed when calling the function URL. For example: `[\"GET\", \"POST\", \"DELETE\"]`, or the wildcard character (`[\"*\"]`).",
        "allow_origins": "(Optional) The origins that can access the function URL. You can list any number of specific origins (or the wildcard character (`\"*\"`)), separated by a comma. For example: `[\"https://www.example.com\", \"http://localhost:60905\"]`.",
        "expose_headers": "(Optional) The HTTP headers in your function response that you want to expose to origins that call the function URL.",
        "max_age": "(Optional) The maximum amount of time, in seconds, that web browsers can cache results of a preflight request. By default, this is set to `0`, which means that the browser doesn't cache results. The maximum value is `86400`."
      },
      "function_name": "(Required) The name (or ARN) of the Lambda function.",
      "invoke_mode": "(Optional) Determines how the Lambda function responds to an invocation. Valid values are `BUFFERED` (default) and `RESPONSE_STREAM`. See more in [Configuring a Lambda function to stream responses](https://docs.aws.amazon.com/lambda/latest/dg/configuration-response-streaming.html).",
      "qualifier": "(Optional) The alias name or `\"$LATEST\"`."
    },
    "s3control_object_lambda_access_point": {
      "account_id": "(Optional) The AWS account ID for the owner of the bucket for which you want to create an Object Lambda Access Point. Defaults to automatically determined account ID of the Terraform AWS provider.",
      "configuration": "(Required) A configuration block containing details about the Object Lambda Access Point. See [Configuration](#configuration) below for more details.",
      "name": "(Required) The name for this Object Lambda Access Point.",
      "allowed_features": "(Optional) Allowed features. Valid values: `GetObject-Range`, `GetObject-PartNumber`.",
      "cloud_watch_metrics_enabled": "(Optional) Whether or not the CloudWatch metrics configuration is enabled.",
      "supporting_access_point": "(Required) Standard access point associated with the Object Lambda Access Point.",
      "transformation_configuration": "(Required) List of transformation configurations for the Object Lambda Access Point. See [Transformation Configuration](#transformation-configuration) below for more details.",
      "actions": "(Required) The actions of an Object Lambda Access Point configuration. Valid values: `GetObject`.",
      "content_transformation": "(Required) The content transformation of an Object Lambda Access Point configuration. See [Content Transformation](#content-transformation) below for more details.",
      "aws_lambda": "(Required) Configuration for an AWS Lambda function. See [AWS Lambda](#aws-lambda) below for more details.",
      "function_arn": "(Required) The Amazon Resource Name (ARN) of the AWS Lambda function.",
      "function_payload": "(Optional) Additional JSON that provides supplemental data to the Lambda function used to transform objects."
    }
  },
  "data": {
    "lambda_function": {
      "function_name": "(Required) Name of the lambda function.",
      "qualifier": "(Optional) Alias name or version number of the lambda functionE.g., `$LATEST`, `my-alias`, or `1`. When not included: the data source resolves to the most recent published version; if no published version exists: it resolves to the most recent unpublished version."
    },
    "lambda_invocation": {
      "function_name": "(Required) Name of the lambda function.",
      "input": "(Required) String in JSON format that is passed as payload to the lambda function.",
      "qualifier": "(Optional) Qualifier (a.k.a version) of the lambda function. Defaults"
    }
  }
}